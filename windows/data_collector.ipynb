{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA COLLECTOR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path of data in local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/Master/BDMA/Courses/Semester_2/Big_Data_Management/Project/dataimporta/windows/rawdata/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the files to be loaded in the temporal landing zone (HDFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CUCI.csv',\n",
       " 'ISIC .csv',\n",
       " 'MUN.csv',\n",
       " 'NCM.csv',\n",
       " 'NCM_FAT_AGREG.csv',\n",
       " 'NCM_PPE.csv',\n",
       " 'PAIS.csv',\n",
       " 'SH.csv',\n",
       " 'UF.csv']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files2load = os.listdir(path)\n",
    "files2load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup logfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "if (logger.hasHandlers()):\n",
    "    logger.handlers.clear()\n",
    "handler = logging.FileHandler('logfile.log')\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the files in the temporal landing zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['hadoop', 'fs', '-put', 'D:/Master/BDMA/Courses/Semester_2/Big_Data_Management/Project/dataimporta/windows/rawdata/CUCI.csv', '/temporal/brazil/metadata'], returncode=0, stdout=b'', stderr=b'')\n",
      " CUCI.csv removed successfully from local filesystem\n",
      "CompletedProcess(args=['hadoop', 'fs', '-put', 'D:/Master/BDMA/Courses/Semester_2/Big_Data_Management/Project/dataimporta/windows/rawdata/ISIC .csv', '/temporal/brazil/metadata'], returncode=0, stdout=b'', stderr=b'')\n",
      " ISIC .csv removed successfully from local filesystem\n",
      "CompletedProcess(args=['hadoop', 'fs', '-put', 'D:/Master/BDMA/Courses/Semester_2/Big_Data_Management/Project/dataimporta/windows/rawdata/MUN.csv', '/temporal/brazil/metadata'], returncode=0, stdout=b'', stderr=b'')\n",
      " MUN.csv removed successfully from local filesystem\n",
      "CompletedProcess(args=['hadoop', 'fs', '-put', 'D:/Master/BDMA/Courses/Semester_2/Big_Data_Management/Project/dataimporta/windows/rawdata/NCM.csv', '/temporal/brazil/metadata'], returncode=0, stdout=b'', stderr=b'')\n",
      " NCM.csv removed successfully from local filesystem\n",
      "CompletedProcess(args=['hadoop', 'fs', '-put', 'D:/Master/BDMA/Courses/Semester_2/Big_Data_Management/Project/dataimporta/windows/rawdata/NCM_FAT_AGREG.csv', '/temporal/brazil/metadata'], returncode=0, stdout=b'', stderr=b'')\n",
      " NCM_FAT_AGREG.csv removed successfully from local filesystem\n",
      "CompletedProcess(args=['hadoop', 'fs', '-put', 'D:/Master/BDMA/Courses/Semester_2/Big_Data_Management/Project/dataimporta/windows/rawdata/NCM_PPE.csv', '/temporal/brazil/metadata'], returncode=0, stdout=b'', stderr=b'')\n",
      " NCM_PPE.csv removed successfully from local filesystem\n",
      "CompletedProcess(args=['hadoop', 'fs', '-put', 'D:/Master/BDMA/Courses/Semester_2/Big_Data_Management/Project/dataimporta/windows/rawdata/PAIS.csv', '/temporal/brazil/metadata'], returncode=0, stdout=b'', stderr=b'')\n",
      " PAIS.csv removed successfully from local filesystem\n",
      "CompletedProcess(args=['hadoop', 'fs', '-put', 'D:/Master/BDMA/Courses/Semester_2/Big_Data_Management/Project/dataimporta/windows/rawdata/SH.csv', '/temporal/brazil/metadata'], returncode=0, stdout=b'', stderr=b'')\n",
      " SH.csv removed successfully from local filesystem\n",
      "CompletedProcess(args=['hadoop', 'fs', '-put', 'D:/Master/BDMA/Courses/Semester_2/Big_Data_Management/Project/dataimporta/windows/rawdata/UF.csv', '/temporal/brazil/metadata'], returncode=0, stdout=b'', stderr=b'')\n",
      " UF.csv removed successfully from local filesystem\n"
     ]
    }
   ],
   "source": [
    "for file in files2load:\n",
    "\n",
    "    # Get time\n",
    "    time = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "    # Load data to HDFS from local filesystem\n",
    "    load_hdfs = subprocess.run(['hadoop', 'fs', '-put', path+file, '/temporal/brazil/metadata'], capture_output=True, shell=True)\n",
    "\n",
    "    # Remove data from local filesystem\n",
    "    try:\n",
    "        os.remove(path+file)\n",
    "        delete_local = \" % s removed successfully from local filesystem\" % file\n",
    "    except OSError as error:\n",
    "        print(error)\n",
    "        delete_local = \" File path can not be removed\"\n",
    "\n",
    "    # Print outcomes\n",
    "    print(load_hdfs)\n",
    "    print(delete_local)\n",
    "\n",
    "    # Register in log\n",
    "    logger.error(time)\n",
    "    logger.error(load_hdfs)\n",
    "    logger.error(delete_local)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the loading of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Found 2 items\\r\\n-rw-r--r--   1 spost supergroup       1242 2022-04-02 15:12 /temporal/chile/metadata/imp/EXPheaders.csv\\r\\n-rw-r--r--   1 spost supergroup      17221 2022-04-02 13:48 /temporal/chile/metadata/imp/descripcion-y-estructura-de-datos-dus.xlsx\\r\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = subprocess.run('hadoop fs -ls /temporal/chile/metadata/imp', capture_output=True, shell=True)\n",
    "x.stdout"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd040cd6d2f6c03fa7abba4128c8b33c22dfb22c58d45ceefc9f5658edabb3e8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('bdm_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
