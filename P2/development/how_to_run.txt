CREATE DATABASE

To create the database run:
% \i create_db.sql


DATA FORMATTER

Once the DB has been created it can be populated with data prepared and cleaned in pyspark.
Needed packages: pyspark.
Note: we decided to use the metadata as they are downloaded from the sources instead of converting them into avro. The default path for data (avro) and metadata (txt, csv) is set to be pointing to the local test_data directory, containing them in the same structure as hdfs. To connect the script to HDFS, change the path in the script defining 'hdfs_path'.

% python3 data_formatter.py



MACHINE LEARNING MODEL

Instal packages in R with:
install.packages('remotes')
install.packages('RPostgres')
install.packages("sparklyr")


To train the model, from command line launch:

% Rscript --default-packages=RPostgres,dplyr,sparklyr train_model_transp_price.R

To do forecasts:

% Rscript --default-packages=sparklyr,RPostgres forecasts_model_transp_price.R path_to_model country mean_of_transport custom net_price net_price_unit     